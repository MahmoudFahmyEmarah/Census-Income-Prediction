# Census Income Prediction - Complete Project

## ğŸ¯ Project Overview

This is a comprehensive data science project that predicts income levels using U.S. Census data. The project demonstrates the complete machine learning pipeline from data exploration to production deployment, achieving **99.3% ROC-AUC** with advanced feature engineering and ensemble methods.

## ğŸ“¦ project Contents

```
census_income_complete_package/
â”œâ”€â”€ README.md                           # This file - setup instructions
â”œâ”€â”€ WINDOWS_SETUP_GUIDE.md             # Detailed Windows setup guide
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ config.py                          # Configuration settings
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                           # Original dataset files
â”‚       â”œâ”€â”€ census_income_learn.csv    # Training data (199,523 samples)
â”‚       â”œâ”€â”€ census_income_test.csv     # Test data (99,762 samples)
â”‚       â””â”€â”€ census_income_metadata.txt # Dataset documentation
â”œâ”€â”€ src/                               # Source code modules
â”‚   â”œâ”€â”€ data_pipeline.py              # Phase 1: Data Infrastructure & EDA
â”‚   â”œâ”€â”€ preprocessing.py              # Phase 2: Data Preprocessing & Feature Engineering
â”‚   â””â”€â”€ model_development.py          # Phase 3: Model Development & Selection
â”œâ”€â”€ notebooks/                         # Jupyter notebooks for testing
â”‚   â”œâ”€â”€ phase1_testing.ipynb          # Phase 1 testing notebook
â”‚   â”œâ”€â”€ phase2_testing.ipynb          # Phase 2 testing notebook
â”‚   â””â”€â”€ phase3_testing.ipynb          # Phase 3 testing notebook
â”œâ”€â”€ reports/                           # Generated reports and visualizations
â”œâ”€â”€ models/                            # Trained model artifacts
â”œâ”€â”€ logs/                              # Execution logs
â”œâ”€â”€ tests/                             # Test scripts
â”œâ”€â”€ docker/                            # Docker configuration
â”œâ”€â”€ api/                               # API endpoints
â””â”€â”€ streamlit_app/                     # Web application
    â”œâ”€â”€ app.py                         # Main Streamlit application
    â”œâ”€â”€ utils/                         # Utility modules
    â”‚   â””â”€â”€ model_loader.py           # Model loading utilities
    â””â”€â”€ requirements.txt               # Streamlit dependencies
```

## ğŸš€ Quick Start (Windows)

### Prerequisites
- **Python 3.11** (Download from https://python.org)
- **Git** (Download from https://git-scm.com)
- **Windows 10/11** with PowerShell or Command Prompt

### Step 1: Extract and Setup
```bash
# Extract the ZIP file to your desired location
# Open PowerShell/Command Prompt and navigate to the project folder
cd path\to\census_income_complete_package

# Create virtual environment
python -m venv venv

# Activate virtual environment
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Step 2: Run Individual Phases

#### Phase 1: Data Infrastructure & EDA
```bash
python src/data_pipeline.py
```
**Expected Output:**
- Data quality report
- 7 comprehensive visualizations
- Data leakage analysis
- EDA summary report

#### Phase 2: Data Preprocessing & Feature Engineering
```bash
python src/preprocessing.py
```
**Expected Output:**
- Processed datasets (188 engineered features)
- Preprocessing pipeline
- Feature engineering report
- Balanced training data

#### Phase 3: Model Development & Selection
```bash
python src/model_development.py
```
**Expected Output:**
- 5 trained models (Logistic Regression, Random Forest, XGBoost, LightGBM, Neural Network)
- Cross-validation results
- Model comparison report
- Feature importance analysis

### Step 3: Launch Web Application
```bash
cd streamlit_app
pip install -r requirements.txt
streamlit run app.py
```
**Access:** http://localhost:8501

## ğŸ“Š Expected Results

### Model Performance
- **XGBoost**: 99.30% ROC-AUC, 96.32% Accuracy
- **LightGBM**: 99.30% ROC-AUC, 96.25% Accuracy  
- **Random Forest**: 99.01% ROC-AUC, 95.16% Accuracy
- **Neural Network**: 96.76% ROC-AUC, 91.06% Accuracy
- **Logistic Regression**: 94.11% ROC-AUC, 86.83% Accuracy

### Data Processing
- **Original Features**: 41
- **Engineered Features**: 188 (370% increase)
- **Training Samples**: 199,523 â†’ 152,807 (after duplicate removal)
- **Class Balance**: 93.8% vs 6.2% â†’ 50% vs 50% (balanced)


## ğŸ“ File Descriptions

### Core Scripts
- **`src/data_pipeline.py`**: Complete EDA with 41 feature visualizations, data leakage detection
- **`src/preprocessing.py`**: Advanced feature engineering, missing value handling, class balancing
- **`src/model_development.py`**: 5 ML models with hyperparameter tuning and cross-validation

### Configuration
- **`config.py`**: All project settings, paths, and parameters
- **`requirements.txt`**: Python package dependencies

### Web Application
- **`streamlit_app/app.py`**: Interactive web interface with live predictions
- **`streamlit_app/utils/model_loader.py`**: Model loading and prediction utilities

## ğŸ¯ Phase-by-Phase Execution

### Phase 1: Data Infrastructure & EDA
```bash
python src/data_pipeline.py
```
**Generates:**
- `reports/data_quality_report.csv`
- `reports/data_leakage_report.txt`
- `reports/eda_report.md`
- `reports/visualizations/` (7 charts)

### Phase 2: Data Preprocessing 
```bash
python src/preprocessing.py
```
**Generates:**
- `models/preprocessing_pipeline.pkl`
- `models/processed_data.pkl`
- `reports/preprocessing_report.md`

### Phase 3: Model Development 
```bash
python src/model_development.py
```
**Generates:**
- `models/` (5 trained models)
- `reports/model_comparison.png`
- `reports/model_development_summary.txt`

### Phase 4: Web Application (Instant)
```bash
cd streamlit_app
streamlit run app.py
```
**Features:**
- Interactive dashboard
- Live predictions
- Model comparison
- Feature importance analysis

## ğŸŒ Web Application Features

### Dashboard
- Real-time performance metrics
- Model comparison charts
- Dataset statistics
- Professional styling

### Live Predictions
- User-friendly input forms
- Real-time classification
- Confidence scoring
- Sample data testing

### Analytics
- Feature importance visualization
- Model performance comparison
- Data insights and statistics
- Business intelligence
